// import { encode, isWithinTokenLimit } from 'gpt-tokenizer';

export const contextTokenLimit = 500;

// export const tokenizer = (context: string) => {
//   return encode(context);
// };

// export const limitCounter = (context: string) => {
//   const withinTokenLimit = isWithinTokenLimit(context, contextTokenLimit);

//   return withinTokenLimit;
// };
